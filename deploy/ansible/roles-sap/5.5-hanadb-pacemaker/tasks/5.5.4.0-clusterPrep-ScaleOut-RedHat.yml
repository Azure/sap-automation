---

# RHEL Clustering - Deploy HANA cluster resources
# Azure ref: https://docs.microsoft.com/en-us/azure/virtual-machines/workloads/sap/sap-hana-high-availability-rhel

# @TODO Subscribe to subscriptions/repos if required
# This code assumes the deployment is using RHEL SAP image

# SAP HANA Cluster resources prep for ANF
# https://learn.microsoft.com/en-us/azure/sap/workloads/sap-hana-high-availability-netapp-files-red-hat


# +------------------------------------4--------------------------------------*/
- name:                            "Backward Compatibility - Check required Database HA variables"
  ansible.builtin.set_fact:
    database_high_availability:    "{{ db_high_availability | default(false) }}"
  when:
    - db_high_availability is defined
    - database_high_availability is not defined

# We set this to prevent code overflow. Since pacemaker code for both AFS and ANF are the same barring NFS mount options, we parameterize this parameter.
- name:                            "NFS Compatibility - set mount options based on NFS source"
  ansible.builtin.set_fact:
    nfs_mount_options:             "{% if NFS_provider == 'ANF' %}bind,defaults,rw,hard,rsize=262144,wsize=262144,proto=tcp,noatime,_netdev,nfsvers=4.1,lock,sec=sys{% else %}noresvport,bind,defaults,rw,hard,proto=tcp,noatime,nfsvers=4.1,lock{% endif %}"

- name:                            "Scale-Out Cluster Compatibility - Fetch majority maker node name"
  ansible.builtin.set_fact:
    majority_maker:                "{{ (query('inventory_hostnames', '{{ sap_sid | upper }}_OBSERVER_DB'))[0] }}"

  # Ref : https://learn.microsoft.com/en-us/azure/sap/workloads/sap-hana-high-availability-scale-out-hsr-rhel?tabs=lb-portal#create-file-system-resources
- name:                                "Configure the ANF/AFS file system resources"
  when:
    - database_high_availability
    - db_scale_out
    - NFS_provider in ["ANF","AFS"]
    - hana_shared_mountpoint is defined
    - hana_shared_mountpoint | length > 1
  block:
    # - name:                            "Get the cluster maintenance mode status"
    #   ansible.builtin.shell:           pcs property show maintenance-mode
    #   register:                        get_status_maintenance_mode
    #   changed_when:                    false
    #   ignore_errors:                   true

    # - name:                            "Set the cluster maintenance mode if not already in maintenance mode"
    #   ansible.builtin.shell:           pcs property set maintenance-mode=true
    #   when: >-
    #     get_status_maintenance_mode.stdout is not search('maintenance-mode') or
    #     get_status_maintenance_mode.stdout is search('maintenance-mode: false')
    - name:                            Stop HANA System on both sites
      block:
        - name:                            Execute HANA StopSystem on both sites
          become_user:                     "{{ db_sid | lower }}adm"
          become:                          true
          ansible.builtin.command:         "{{ sapcontrol_command }} -function StopSystem"
          failed_when:                     false
          changed_when:                    false
          register:                        hana_system_stopped
          when:                            ansible_hostname in ["{{ primary_instance_name }}","{{ secondary_instance_name }}"]

    - name:                            Wait 2 minutes for SAP system to stop
      ansible.builtin.pause:
        seconds:                       120

    - name:                            Unmount /hana/shared from all cluster participating nodes
      block:
        - name:                        "Comment out the mountpoint from '/etc/fstab' file"
          ansible.builtin.replace:
            path:                      /etc/fstab
            regexp:                    "^{{ item }}"
            replace:                   "# {{ item }}"
            backup:                    true
          loop:
            - "{{ hana_shared_mountpoint[0] }}"
            - "{{ hana_shared_mountpoint[1] }}"

      #   - name:                     Unmount /hana/shared from all cluster participating nodes
      #     ansible.builtin.mount:
      #       path:                   /hana/shared
      #       state:                  unmounted
      #     register:                 unmount_result
      #     failed_when:              unmount_result.rc != 0
      # rescue:
      #   - name:                            Check if any processes are locking /hana/shared
      #     ansible.builtin.shell:           lsof +f -- /hana/shared
      #     register:                        lock_processes
      #     changed_when:                    false

      #   # Fix this
      #   - name:                            Kill processes locking /hana/shared
      #     ansible.builtin.shell:           kill -9 {{ item.split()[1] }}
      #     with_items:                      "{{ lock_processes.stdout_lines }}"
      #     when:                            lock_processes.stdout_lines | length > 0

      #   - name:                        "Comment out the mountpoint from '/etc/fstab' file"
      #     ansible.builtin.replace:
      #       path:                      /etc/fstab
      #       regexp:                    "^{{ item }}"
      #       replace:                   "# {{ item }}"
      #       backup:                    true
      #     loop:
      #       - "{{ hana_shared_mountpoint[0] }}"
      #       - "{{ hana_shared_mountpoint[1] }}"

      #   - name:                            Unmount /hana/shared forcefully
      #     ansible.builtin.shell:           umount -f /hana/shared



        # TODO : add code to unmount /hana/shared and ensure it remains unmounted as hanarsutil,sapcontrol locks the file system/mount point even after stopping SAP system

    - name:                            "Configure pacemaker hana shared filesystem resources on {{ primary_instance_name }}"
      when:                            ansible_hostname == primary_instance_name
      block:
        - name:                        "Configure filesystem resource in Pacemaker for primary site"
          ansible.builtin.shell: >
                                       pcs resource create hana_shared_s1 --disabled ocf:heartbeat:Filesystem \
                                       device="{{ hana_shared_mountpoint[0] }}" directory="/hana/shared" fstype="nfs" \
                                       options="{{ nfs_mount_options }}" \
                                       op monitor interval=20s on-fail=fence timeout=120s OCF_CHECK_LEVEL=20 \
                                       op start interval=0 timeout=120 op stop interval=0 timeout=120 \
          register:                    nfs_mount_site1
          failed_when:                 nfs_mount_site1.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list
          ignore_errors:               true

        # - name:                        "Check if ANF hana mounts did not error for primary site"
        #   ansible.builtin.set_fact:
        #     chk_nfs_mount_site1:      "{{ nfs_mount_site1.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list }}"

        # - name:                        "Fail when ANF hana mounts errored on primary site"
        #   ansible.builtin.fail:
        #     msg:                       "Failed to create ANF hana mounts on primary site"
        #   when:
        #     - chk_nfs_mount_site1 | length > 0
        #     - ansible_hostname == primary_instance_name

        - name:                        "Configure filesystem resource in Pacemaker for secondary site"
          ansible.builtin.shell: >
                                      pcs resource create hana_shared_s1 --disabled ocf:heartbeat:Filesystem \
                                       device="{{ hana_shared_mountpoint[1] }}" directory="/hana/shared" fstype="nfs" \
                                       options="{{ nfs_mount_options }}" \
                                       op monitor interval=20s on-fail=fence timeout=120s OCF_CHECK_LEVEL=20 \
                                       op start interval=0 timeout=120 op stop interval=0 timeout=120 \
          register:                    nfs_mount_site2
          failed_when:                 nfs_mount_site2.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list
          ignore_errors:               true

        # - name:                        "Check if ANF hana mounts did not error for secondary site"
        #   ansible.builtin.set_fact:
        #     chk_nfs_mount_site2:      "{{ nfs_mount_site2.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list }}"

        # - name:                        "Fail when ANF hana mounts errored on secondary site"
        #   ansible.builtin.fail:
        #     msg:                       "Failed to create ANF hana mounts on secondary site"
        #   when:
        #     - chk_nfs_mount_site2 | length > 0

        - name:                        "Clone the primary site filesystem resource"
          ansible.builtin.shell: >
                                       pcs resource clone fs_hana_shared_s1 meta clone-node-max=1 interleave=true
          register:                    nfs_mount_clone_site1
          failed_when:                 nfs_mount_clone_site1.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list
          ignore_errors:               true

        # - name:                        "Check if the filesystem resource clone was created for the primary site"
        #   ansible.builtin.set_fact:
        #     chk_nfs_mount_clone_site1:      "{{ nfs_mount_clone_site1.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list }}"

        # - name:                        "Fail when filesystem resource clone errored on primary site"
        #   ansible.builtin.fail:
        #     msg:                       "Failed to create FileSystem clone for  hana mounts on primary site"
        #   when:
        #     - chk_nfs_mount_clone_site1 | length > 0

        - name:                        "Clone the secondary site filesystem resource"
          ansible.builtin.shell: >
                                       pcs resource clone fs_hana_shared_s2 meta clone-node-max=1 interleave=true
          register:                    nfs_mount_clone_site2
          failed_when:                 nfs_mount_clone_site2.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list
          ignore_errors:               true

        # - name:                        "Check if the filesystem resource clone was created for the secondary site"
        #   ansible.builtin.set_fact:
        #     chk_nfs_mount_clone_site2:      "{{ nfs_mount_clone_site2.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list }}"

        # - name:                        "Fail when filesystem resource clone errored on secondary site"
        #   ansible.builtin.fail:
        #     msg:                       "Failed to create FileSystem clone for  hana mounts on secondary site"
        #   when:
        #     - chk_nfs_mount_clone_site2 | length > 0

        - name:                        "Configure node attributes for primary site cluster nodes"
          ansible.builtin.shell: >
                                       pcs noe attribute {{ item }} NFS_{{ db_sid | upper }}_SITE=S1
          register:                    node_nfs_attribute_site1
          failed_when:                 false
          ignore_errors:               true
          loop:
            - ansible_play_hosts_all[0::2]

        - name:                        "Configure node attributes for secondary site cluster nodes"
          ansible.builtin.shell: >
                                       pcs node attribute {{ item }} NFS_{{ db_sid | upper }}_SITE=S2
          register:                    node_nfs_attribute_site2
          failed_when:                 false
          ignore_errors:               true
          loop:
            - ansible_play_hosts_all[2::2]

        - name:                        "Configure location constraint for filesystem resource clone for primary site"
          ansible.builtin.shell: >
                                       pcs constraint location fs_hana_shared_s1-clone rule resource-discovery=never score=-INFINITY NFS_{{ db_did | upper }}_SITE ne S1
          register:                    location_nfs_attribute_site1
          failed_when:                 false
          ignore_errors:               true

        - name:                        "Configure location constraint for filesystem resource clone for secondary site"
          ansible.builtin.shell: >
                                       pcs constraint location fs_hana_shared_s2-clone rule resource-discovery=never score=-INFINITY NFS_{{ db_did | upper }}_SITE ne S2
          register:                    location_nfs_attribute_site2
          failed_when:                 false
          ignore_errors:               true

        - name:                        Activate filesystem resource on primary site
          ansible.builtin.shell: >
                                       pcs resource enable fs_hana_shared_s1
          register:                    activate_nfs_mount_site1
          failed_when:                 false
          ignore_errors:               true
          when:
            - chk_nfs_mount_clone_site1 | length == 0

        - name:                        Activate filesystem resource on secondary site
          ansible.builtin.shell: >
                                       pcs resource enable fs_hana_shared_s2
          register:                    activate_nfs_mount_site2
          failed_when:                 false
          ignore_errors:               true
          when:
            - chk_nfs_mount_clone_site2 | length == 0
        # TODO : add code to check if this failed or not

        - name:                        Configure pacemaker attribute resource for primary site
          ansible.builtin.shell: >
                                       pcs resource create hana_nfs_s1_active ocf:pacemaker:attribute active_value=true inactive_value=false name=hana_nfs_s1_active
          register:                    attribute_hana_nfs_s1
          failed_when:                 false
          ignore_errors:               true

        - name:                        Configure pacemaker attribute resource for secondary site
          ansible.builtin.shell: >
                                       pcs resource create hana_nfs_s2_active ocf:pacemaker:attribute active_value=true inactive_value=false name=hana_nfs_s2_active
          register:                    attribute_hana_nfs_s2
          failed_when:                 false
          ignore_errors:               true

        - name:                        Clone pacemaker attribute resource for primary site
          ansible.builtin.shell: >
                                       pcs resource clone hana_nfs_s1_active meta clone-node-max=1 interleave=true
          register:                    clone_attribute_hana_nfs_s1
          failed_when:                 false
          ignore_errors:               true

        - name:                        Clone pacemaker attribute resource for secondary site
          ansible.builtin.shell: >
                                       pcs resource clone hana_nfs_s2_active meta clone-node-max=1 interleave=true
          register:                    clone_attribute_hana_nfs_s2
          failed_when:                 false
          ignore_errors:               true


        - name:                        Create constraints for  pacemaker attribute resource for primary site
          ansible.builtin.shell: >
                                       pcs constraint order fs_hana_shared_s1-clone then hana_nfs_s1_active-clone
          register:                    loc_attribute_hana_nfs_s1
          failed_when:                 false
          ignore_errors:               true

        - name:                        Create constraints for  pacemaker attribute resource for secondary site
          ansible.builtin.shell: >
                                       pcs constraint order fs_hana_shared_s2-clone then hana_nfs_s2_active-clone
          register:                    loc_attribute_hana_nfs_s2
          failed_when:                 false
          ignore_errors:               true

    - name:                            Start HANA System on both nodes
      become_user:                     "{{ db_sid | lower }}adm"
      become:                          true
      ansible.builtin.command:         "{{ sapcontrol_command }} -function StartSystem"
      failed_when:                     false
      changed_when:                    false
      register:                        hana_system_started

    - name:                            Wait 5 minutes for SAP system to start
      ansible.builtin.pause:
        seconds:                       300
# End of HANA clustering resources
