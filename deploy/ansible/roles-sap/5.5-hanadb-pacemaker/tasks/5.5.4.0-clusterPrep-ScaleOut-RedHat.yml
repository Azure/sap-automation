---

# RHEL Clustering - Deploy HANA cluster resources
# Azure ref: https://docs.microsoft.com/en-us/azure/virtual-machines/workloads/sap/sap-hana-high-availability-rhel

# @TODO Subscribe to subscriptions/repos if required
# This code assumes the deployment is using RHEL SAP image

# SAP HANA Cluster resources prep for ANF
# https://learn.microsoft.com/en-us/azure/sap/workloads/sap-hana-high-availability-netapp-files-red-hat


# +------------------------------------4--------------------------------------*/
- name:                            "Backward Compatibility - Check required Database HA variables"
  ansible.builtin.set_fact:
    database_high_availability:    "{{ db_high_availability | default(false) }}"
  when:
    - db_high_availability is defined
    - database_high_availability is not defined
- name:                            "NFS Compatibility - set mount options based on NFS source"
  ansible.builtin.set_fact:
    nfs_mount_options:             "{% if NFS_provider == 'ANF' %}bind,defaults,rw,hard,rsize=262144,wsize=262144,proto=tcp,noatime,_netdev,nfsvers=4.1,lock,sec=sys{% else %}bind,defaults,rw,hard,proto=tcp,noatime,nfsvers=4.1,lock{% endif %}"

- name:                            "Scale-Out Cluster Compatibility - Fetch majority maker node name"
  ansible.builtin.set_fact:
    majority_maker:                "{{ (query('inventory_hostnames', '{{ sap_sid | upper }}_OBSERVER_DB'))[0] }}"


- name:                            "Configure the ANF file system resources"
  when:
    - database_high_availability
    - hana_shared_mountpoint is defined
    - hana_shared_mountpoint | length > 1
    - playform | upper = 'HANA'
  block:
    - name:                            "Get the cluster maintenance mode status"
      ansible.builtin.shell:           pcs property show maintenance-mode
      register:                        get_status_maintenance_mode
      changed_when:                    false
      ignore_errors:                   true

    - name:                            "Set the cluster maintenance mode if not already in maintenance mode"
      ansible.builtin.shell:           pcs property set maintenance-mode=true
      when: >-
        get_status_maintenance_mode.stdout is not search('maintenance-mode') or
        get_status_maintenance_mode.stdout is search('maintenance-mode: false')
        ansible_hostname == primary_instance_name

    - name:                            Stop HANA System on both sites
      become_user:                     "{{ db_sid | lower }}adm"
      become:                          true
      ansible.builtin.command:         "{{ sapcontrol_command }} -function StopSystem"
      failed_when:                     false
      changed_when:                    false
      register:                        hana_system_stopped
      when:
        - ansible_hostname == primary_instance_name or ansible_hostname == secondary_instance_name

    - name:                            Wait 2 minutes for SAP system to stop
      ansible.builtin.pause:
        seconds:                       120

    # Ref :https://learn.microsoft.com/en-us/azure/sap/workloads/sap-hana-high-availability-scale-out-hsr-rhel?tabs=lb-portal#create-file-system-resources
    # Pacemaker will control where and when /hana/shared will be mounted. All remaining volumes are mounted on managed disks.
    - name:                           "Comment out the mountpoints on HANA node from '/etc/fstab' file"
      ansible.builtin.replace:
        path:                      /etc/fstab
        regexp:                    "^{{ item }}"
        replace:                   "# {{ item }}"
        backup:                    true
        loop:
          - "{{ hana_shared_mountpoint[0] }}/hanashared"
          - "{{ hana_shared_mountpoint[1] }}/hanashared"

    # All tasks this point forwards runs on primary node/first node in the DB list
    - name:                            "Configure HANA Shared mounts on {{ primary_instance_name }}"
      when:                            ansible_hostname == primary_instance_name
      block:
        - name:                        "Configure filesystem resource in Pacemaker"
          ansible.builtin.shell: >
                                       pcs resource create fs_hana_shared_{{ item.site_code | lower }} --disabled ocf:heartbeat:Filesystem \
                                       device="{{ item.fs_mount }}" directory="{{ item.fs_dir }}" fstype="nfs" \
                                       options="{{ nfs_mount_options }}" \
                                       op monitor interval=20s on-fail=fence timeout=120s OCF_CHECK_LEVEL=20 \
                                       op start internal=0 timeout=120 op stop interval=0 timeout=120
          register:                    nfs_mounts_node
          failed_when:                 false
          ignore_errors:               true
          loop:
            - { site_code: 'S1',fs_mount: '{{ hana_shared_mountpoint[0] }}/hanashared', fs_dir: '/hana/shared' }
            - { site_code: 'S1',fs_mount: '{{ hana_shared_mountpoint[1] }}/hanashared', fs_dir: '/hana/shared' }
          loop_control:
            loop_var:                  item

        - name:                        "Check if HANA Shared mounts did not error on {{ primary_instance_name }}"
          ansible.builtin.set_fact:
            chk_nfs_mounts_node1:      "{{ nfs_mounts_node1.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | default([]) | list }}"

        - name:                        "Fail when HANA Shared mounts errored on {{ primary_instance_name }}"
          ansible.builtin.fail:
            msg:                       "Failed to create ANF hana mounts on {{ primary_instance_name }}"
          when:                        chk_nfs_mounts_node1 | length > 0

        - name:                        "Clone the /hana/shared file system resource for both sites"
          ansible.builtin.shell: >
                                       pcs resource clone fs_hana_shared_{{ item.site_code | lower}} meta clone-node-max=1 interleave=true
          register:                    nfs_mounts_node2
          failed_when:                 false
          ignore_errors:               true
          loop:
            - { site_code: 'S1' }
            - { site_code: 'S2' }
          loop_control:
            loop_var:                  item

        - name:                        "Configure location constraints and attribute resources"
          block:
          - name:                        "Configure site node attributes for primary site"
            ansible.builtin.shell: >
                                         pcs node attribute {{ item.hostname }} NFS_SID_SITE=S1
            register:                    is_nfs_primary_configured
            failed_when:                 false
            ignore_errors:               true
            loop:
              - ansible_play_hosts_all[0::2]
            loop_control:
              loop_var:                  item

          - name:                        "Configure site node attributes for secondary site"
            ansible.builtin.shell: >
                                         pcs node attribute {{ item.hostname }} NFS_SID_SITE=S2
            register:                    is_nfs_secondary_configured
            failed_when:                 false
            ignore_errors:               true
            loop:
              - ansible_play_hosts_all[1::2]
            loop_control:
              loop_var:                  item

          - name:                        "Configure location constraints"
            ansible.builtin.shell: >
                                         pcs constraint location fs_hana_shared_{{ item.site_code | lower }}-clone rule resource-discovery=never score=-INFINITY NFS_SID_SITE ne {{ item._site_code | upper }}
            register:                    nfs_location_constraints
            failed_when:                 false
            ignore_errors:               true
            loop:
              - { site_code: "S1" }
              - { site_code: "S2" }
            loop_control:
              loop_var:                  item
            when:                        is_nfs_secondary_configured and is_nfs_primary_configured





        - name:                        "Check if location constraints did not error on {{ primary_instance_name }}"
          ansible.builtin.set_fact:
            chk_nfs_location_constraints: "{{ nfs_location_constraints.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | list }}"

        - name:                        "Fail when location constraints errored on {{ primary_instance_name }}"
          ansible.builtin.fail:
            msg:                        "Failed to create location constraints on {{ primary_instance_name }}"
          when:                         chk_nfs_location_constraints | length > 0

        - name:                        "Configure attribute resources"
          ansible.builtin.shell: >
                                       pcs resource create {{ item.attribute_name }} ocf:pacemaker:attribute
                                       active_value=true inactive_value=false name={{ item.attribute_name }}
          register:                    nfs_attribute_resources
          failed_when:                 false
          ignore_errors:               true
          loop:
            - { attribute_name: 'attr_hana_{{ db_sid | upper }}_NFS_1_active' }
            - { attribute_name: 'attr_hana_{{ db_sid | upper }}_NFS_2_active' }
          loop_control:
            loop_var:                  item
          when:                        is_nfs_secondary_configured

        - name:                        "Check if attribute resources did not error on {{ primary_instance_name }}"
          ansible.builtin.set_fact:
            chk_nfs_attribute_resources: "{{ nfs_attribute_resources.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | list }}"

        - name:                        "Fail when attribute resources errored on {{ primary_instance_name }}"
          ansible.builtin.fail:
            msg:                       "Failed to create attribute resources on {{ primary_instance_name }}"
          when:                        chk_nfs_attribute_resources | length > 0

        - name:                        "Configure constraints for attribute resources"
          ansible.builtin.shell: >
                                       pcs constraint location {{ item.attribute_name }} avoids {{ item.node }}
          register:                    nfs_attribute_constraints
          failed_when:                 false
          ignore_errors:               true
          loop:
            - { attribute_name: 'attr_hana_{{ db_sid | upper }}_NFS_1_active', node: '{{ secondary_instance_name }}'}
            - { attribute_name: 'attr_hana_{{ db_sid | upper }}_NFS_2_active', node: '{{ primary_instance_name }}'  }
          loop_control:
            loop_var:                  item
          when:                        is_nfs_secondary_configured

        - name:                        "Check if attribute constraints did not error on {{ primary_instance_name }}"
          ansible.builtin.set_fact:
            chk_nfs_attribute_constraints: "{{ nfs_attribute_constraints.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | list }}"

        - name:                        "Fail when attribute constraints errored on {{ primary_instance_name }}"
          ansible.builtin.fail:
            msg:                       "Failed to create attribute constraints on {{ primary_instance_name }}"
          when:                        chk_nfs_attribute_constraints | length > 0

        - name:                        "Configure ordering constraints for NFS mounts to start before attribute resources"
          ansible.builtin.shell: >
                                       pcs constraint order {{ item.group_name }} then {{ item.attribute_name }}
          register:                    nfs_ordering_constraints
          failed_when:                 false
          ignore_errors:               true
          loop:
            - { group_name: 'g_hana_{{ db_sid | upper }}_NFS_1', attribute_name: 'attr_hana_{{ db_sid | upper }}_NFS_1_active' }
            - { group_name: 'g_hana_{{ db_sid | upper }}_NFS_2', attribute_name: 'attr_hana_{{ db_sid | upper }}_NFS_2_active' }
          loop_control:
            loop_var:                  item
          when:                        is_nfs_secondary_configured

        - name:                        "Check if ordering constraints did not error on {{ primary_instance_name }}"
          ansible.builtin.set_fact:
            chk_nfs_ordering_constraints: "{{ nfs_ordering_constraints.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | list }}"

        - name:                        "Fail when ordering constraints errored on {{ primary_instance_name }}"
          ansible.builtin.fail:
            msg:                       "Failed to create ordering constraints on {{ primary_instance_name }}"
          when:                        chk_nfs_ordering_constraints | length > 0

        # - name:                        "Get the cluster maintenance mode status"
        #   ansible.builtin.shell:       pcs property show maintenance-mode
        #   register:                    get_status_maintenance_mode
        #   changed_when:                false
        #   ignore_errors:               true

        # - name:                        "Get the cluster out of maintenance mode if already in maintenance mode"
        #   ansible.builtin.shell:       pcs property set maintenance-mode=false
        #   when: >-
        #     get_status_maintenance_mode.stdout is search('maintenance-mode') or
        #     get_status_maintenance_mode.stdout is search('maintenance-mode: true')

        - name:                        "pause for 2 minutes"
          ansible.builtin.pause:
            seconds:                   120


    # validation tasks to be run on all HANA hosts
    - name:                            "Validate /hana/shared is mounted on all HANA hosts"
      block:
        - name:                        "Check if NFS share is mounted on primary site nodes"
          ansible.builtin.shell: >
                                       nfsstat -m | grep "{{ target }}"
          register:                    nfs_mount_check_{{ ansible_hostname }}
          failed_when:                 nfs_mount_check.rc != 0
          vars:
            target:                    hana_shared_mountpoint[0]
          when:                        ansible_hostname in ansible_play_hosts_all[0::2]

        - name:                        "Fail when NFS share is not mounted on primary site nodes"
          ansible.builtin.fail:
            msg:                       "NFS share is not mounted on {{ ansible_hostname }}"
          when:                        nfs_mount_check_{{ ansible_hostname }}.rc != 0


















    - name:                            "Enable ANF hana mounts on {{ primary_instance_name }}"
      when:                            ansible_hostname == primary_instance_name
      block:
        - name:                        "Enable filesystem resource in Pacemaker"
          ansible.builtin.shell: >
                                       pcs resource enable {{ item.fs_name }}
          register:                    nfs_mounts_enable_node1
          failed_when:                 false
          ignore_errors:               true
          loop:
            - { fs_name: 'hana_data1'  }
            - { fs_name: 'hana_log1'   }
            - { fs_name: 'hana_shared1'}
          loop_control:
            loop_var:                  item

        - name:                        "Check if ANF hana mounts did not error on {{ primary_instance_name }}"
          ansible.builtin.set_fact:
            chk_nfs_mounts_enable_node1:  "{{ nfs_mounts_enable_node1.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | list }}"

        - name:                        "Fail when ANF hana mounts errored on {{ primary_instance_name }}"
          ansible.builtin.fail:
            msg:                       "Failed to create ANF hana mounts on {{ primary_instance_name }}"
          when:                        chk_nfs_mounts_enable_node1 | length > 0

    - name:                            "Enable ANF hana mounts on {{ secondary_instance_name }}"
      when:                            ansible_hostname == secondary_instance_name
      block:
        - name:                        "Enable filesystem resource in Pacemaker"
          ansible.builtin.shell: >
                                       pcs resource enable {{ item.fs_name }}
          register:                    nfs_mounts_enable_node2
          failed_when:                 false
          ignore_errors:               true
          loop:
            - { fs_name: 'hana_data2'  }
            - { fs_name: 'hana_log2'   }
            - { fs_name: 'hana_shared2'}
          loop_control:
            loop_var:                  item

        - name:                        "Check if ANF hana mounts did not error on {{ secondary_instance_name }}"
          ansible.builtin.set_fact:
            chk_nfs_mounts_enable_node2:  "{{ nfs_mounts_enable_node2.results | selectattr('rc', 'ne', 0) | rejectattr('stderr', 'search', 'already exists') | list }}"

        - name:                        "Fail when ANF hana mounts errored on {{ secondary_instance_name }}"
          ansible.builtin.fail:
            msg:                       "Failed to create ANF hana mounts on {{ secondary_instance_name }}"
          when:                        chk_nfs_mounts_enable_node2 | length > 0

    - name:                            Start HANA System on both nodes
      become_user:                     "{{ db_sid | lower }}adm"
      become:                          true
      ansible.builtin.command:         "{{ sapcontrol_command }} -function StartSystem"
      failed_when:                     false
      changed_when:                    false
      register:                        hana_system_started

    - name:                            Wait 5 minutes for SAP system to start
      ansible.builtin.pause:
        seconds:                       300
# End of HANA clustering resources
